import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from typing import Dict, List

# ====================== 1. é…ç½®æ¨¡å— ======================
def set_config():
    """è®¾ç½®å…¨å±€é…ç½®ï¼ˆä¸­æ–‡å­—ä½“ã€å›¾è¡¨æ ·å¼ï¼‰"""
    # ä¸­æ–‡å­—ä½“é…ç½®
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    # å›¾è¡¨æ ·å¼é…ç½®
    plt.style.use('default')
    # æ•°æ®è·¯å¾„é…ç½®ï¼ˆæ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
    DATA_DIR = "F:\\å¤šå…ƒè®¾è®¡\\raw\\"  # é‡ç‚¹ä¿®æ”¹è¿™é‡Œ
    return DATA_DIR

# ====================== 2. æ•°æ®åŠ è½½æ¨¡å— ======================
def load_all_data(data_dir: str) -> Dict[str, pd.DataFrame]:
    """
    åŠ è½½æ‰€æœ‰CSVæ•°æ®æ–‡ä»¶
    è¿”å›ï¼šå­—å…¸{æ–‡ä»¶å: æ•°æ®æ¡†}
    """
    data_dict = {}
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    
    if not csv_files:
        raise FileNotFoundError(f"åœ¨{data_dir}ç›®å½•ä¸‹æœªæ‰¾åˆ°CSVæ–‡ä»¶")
    
    # é€ä¸ªåŠ è½½æ–‡ä»¶
    for file in csv_files:
        file_path = os.path.join(data_dir, file)
        try:
            df = pd.read_csv(file_path)
            # æ•°æ®é¢„å¤„ç†ï¼šæ¸…ç†åŸå¸‚åç§°ç©ºæ ¼
            if 'èµ·ç‚¹åŸå¸‚' in df.columns:
                df['èµ·ç‚¹åŸå¸‚'] = df['èµ·ç‚¹åŸå¸‚'].str.strip()
            data_dict[file] = df
            print(f"âœ… æˆåŠŸåŠ è½½ï¼š{file}ï¼ˆ{df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—ï¼‰")
        except Exception as e:
            print(f"âŒ åŠ è½½{file}å¤±è´¥ï¼š{str(e)}")
    
    return data_dict

# ====================== 3. åŸºç¡€æ¢ç´¢æ¨¡å— ======================
def basic_data_explore(data_dict: Dict[str, pd.DataFrame]) -> None:
    """
    åŸºç¡€æ•°æ®æ¢ç´¢ï¼šè¾“å‡ºæ–‡ä»¶ç»“æ„ã€æ•°æ®ç±»å‹ã€ç¼ºå¤±å€¼æƒ…å†µ
    """
    print("\n" + "="*60)
    print("ğŸ“Š åŸºç¡€æ•°æ®æ¢ç´¢æŠ¥å‘Š")
    print("="*60)
    
    # åˆ†ç±»æ•´ç†æ–‡ä»¶ï¼ˆODçŸ©é˜µ vs ç»¼åˆæ•°æ®ï¼‰
    od_files = [f for f in data_dict.keys() if 'od_matrix' in f]
    main_file = [f for f in data_dict.keys() if 'main_data' in f][0] if any('main_data' in f for f in data_dict.keys()) else None
    
    # 1. åˆ†æODçŸ©é˜µæ–‡ä»¶
    print("\n1. ODçŸ©é˜µæ–‡ä»¶åˆ†æï¼ˆåŸå¸‚é—´äº¤äº’æ•°æ®ï¼‰ï¼š")
    for file in od_files:
        df = data_dict[file]
        print(f"\nğŸ“„ {file}ï¼š")
        print(f"   åˆ—åï¼š{', '.join(df.columns)}")
        print(f"   æ•°æ®ç±»å‹ï¼š\n{df.dtypes.to_string()}")
        print(f"   ç¼ºå¤±å€¼æ¯”ä¾‹ï¼š{(df.isnull().sum()/len(df)*100).round(2).to_string()}%")
    
    # 2. åˆ†æç»¼åˆæ•°æ®æ–‡ä»¶
    if main_file:
        df_main = data_dict[main_file]
        print(f"\n2. ç»¼åˆæ•°æ®æ–‡ä»¶åˆ†æï¼ˆ{main_file}ï¼‰ï¼š")
        print(f"   æ—¶é—´èŒƒå›´ï¼š{sorted(df_main['å¹´ä»½'].unique())}")
        print(f"   è¦†ç›–åŸå¸‚ï¼š{sorted(df_main['åŸå¸‚'].unique())}")
        print(f"   æ ¸å¿ƒæŒ‡æ ‡åˆ†ç±»ï¼š")
        # æŒ‡æ ‡åˆ†ç±»ï¼ˆåŸºäºå­—æ®µåå…³é”®è¯ï¼‰
        indicator_categories = {
            'æ•°æ®äº§ä¸š': [col for col in df_main.columns if any(key in col for key in ['æ•°æ®', 'API', 'å¸¦å®½', 'ç®—åŠ›', 'æœºæ¶'])],
            'ç»æµå‘å±•': [col for col in df_main.columns if any(key in col for key in ['GDP', 'æ•°å­—ç»æµ', 'å¤–è´¸', 'FDI', 'ç”µå•†'])],
            'ç§‘æŠ€åˆ›æ–°': [col for col in df_main.columns if any(key in col for key in ['ç ”å‘', 'ä¸“åˆ©', 'é«˜æ–°', 'ç§‘æŠ€å‹', 'ç‹¬è§’å…½'])],
            'åŸºç¡€è®¾æ–½': [col for col in df_main.columns if any(key in col for key in ['5G', 'åŸºç«™', 'å…‰ç½‘', 'ç‰©è”ç½‘'])]
        }
        for cate, cols in indicator_categories.items():
            if cols:
                print(f"      - {cate}ï¼ˆ{len(cols)}ä¸ªï¼‰ï¼š{', '.join(cols[:3])}...")

# ====================== 4. æ·±åº¦åˆ†ææ¨¡å— ======================
def deep_data_analysis(data_dict: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
    """
    æ·±åº¦åˆ†æï¼šè®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆå¹´åº¦å¢é•¿ã€åŸå¸‚æ’åã€ç›¸å…³æ€§ï¼‰
    è¿”å›ï¼šåˆ†æç»“æœå­—å…¸
    """
    print("\n" + "="*60)
    print("ğŸ” æ·±åº¦æ•°æ®åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    # 1. æå–æ ¸å¿ƒæ•°æ®
    od_summary = data_dict['od_matrix.csv']  # æ±‡æ€»ODçŸ©é˜µ
    main_data = data_dict['main_data_advanced.csv']  # ç»¼åˆæ•°æ®
    yearly_od_files = [f for f in data_dict.keys() if 'od_matrix_20' in f]  # å¹´åº¦ODçŸ©é˜µ
    
    # 2. è®¡ç®—å¹´åº¦æ•°æ®ä¼ è¾“å¢é•¿
    yearly_transfer = od_summary.groupby('å¹´ä»½')['æ•°æ®ä¼ è¾“é‡_TB'].sum().reset_index()
    growth_rate = ((yearly_transfer.iloc[-1]['æ•°æ®ä¼ è¾“é‡_TB'] - yearly_transfer.iloc[0]['æ•°æ®ä¼ è¾“é‡_TB']) / 
                   yearly_transfer.iloc[0]['æ•°æ®ä¼ è¾“é‡_TB'] * 100)
    print(f"\n1. å¹´åº¦æ•°æ®ä¼ è¾“é‡å¢é•¿åˆ†æï¼š")
    print(f"   2019å¹´æ€»é‡ï¼š{yearly_transfer.iloc[0]['æ•°æ®ä¼ è¾“é‡_TB']:.0f} TB")
    print(f"   2023å¹´æ€»é‡ï¼š{yearly_transfer.iloc[-1]['æ•°æ®ä¼ è¾“é‡_TB']:.0f} TB")
    print(f"   äº”å¹´å¢é•¿ç‡ï¼š{growth_rate:.1f}%")
    
    # 3. 2023å¹´åŸå¸‚é—´äº¤äº’æ’å
    transfer_2023 = od_summary[od_summary['å¹´ä»½'] == 2023]
    top10_transfer = transfer_2023.nlargest(10, 'æ•°æ®ä¼ è¾“é‡_TB')
    print(f"\n2. 2023å¹´æ•°æ®ä¼ è¾“é‡Top5åŸå¸‚å¯¹ï¼š")
    for i, (_, row) in enumerate(top10_transfer.head(5).iterrows(), 1):
        print(f"   {i}. {row['èµ·ç‚¹åŸå¸‚']}â†’{row['ç»ˆç‚¹åŸå¸‚']}ï¼š{row['æ•°æ®ä¼ è¾“é‡_TB']:.0f} TB")
    
    # 4. æ ¸å¿ƒåŸå¸‚æ•°å­—ç»æµæ°´å¹³
    main_2023 = main_data[main_data['å¹´ä»½'] == 2023]
    core_cities = ['å¹¿å·', 'æ·±åœ³', 'é¦™æ¸¯', 'æ¾³é—¨']
    core_econ = main_2023[main_2023['åŸå¸‚'].isin(core_cities)][['åŸå¸‚', 'GDP_äº¿å…ƒ', 'æ•°å­—ç»æµå GDPæ¯”é‡_%']]
    print(f"\n3. 2023å¹´æ ¸å¿ƒåŸå¸‚æ•°å­—ç»æµæ°´å¹³ï¼š")
    print(core_econ.sort_values('æ•°å­—ç»æµå GDPæ¯”é‡_%', ascending=False).to_string(index=False))
    
    # è¿”å›åˆ†æç»“æœ
    analysis_results = {
        'yearly_transfer': yearly_transfer,
        'top10_transfer_2023': top10_transfer,
        'core_city_econ_2023': core_econ,
        'main_2023': main_2023
    }
    return analysis_results

# ====================== 5. å¯è§†åŒ–æ¨¡å— ======================
def create_visualizations(analysis_results: Dict[str, pd.DataFrame], save_path: str = '/mnt/') -> None:
    """
    ç”Ÿæˆ4ä¸ªæ ¸å¿ƒå¯è§†åŒ–å›¾è¡¨ï¼šè¶‹åŠ¿å›¾ã€æ’åå›¾ã€å¯¹æ¯”å›¾ã€å…³ç³»å›¾
    """
    print("\n" + "="*60)
    print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("="*60)
    
    # æå–åˆ†æç»“æœ
    yearly_transfer = analysis_results['yearly_transfer']
    top10_transfer = analysis_results['top10_transfer_2023']
    core_econ = analysis_results['core_city_econ_2023']
    main_2023 = analysis_results['main_2023']
    
    # åˆ›å»º2Ã—2å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Greater Bay Area Digital Economy Analysis (2019-2023)', fontsize=16, fontweight='bold')
    
    # 1. å›¾1ï¼šå¹´åº¦æ•°æ®ä¼ è¾“é‡è¶‹åŠ¿ï¼ˆå·¦ä¸Šï¼‰
    axes[0,0].plot(yearly_transfer['å¹´ä»½'], yearly_transfer['æ•°æ®ä¼ è¾“é‡_TB'], 
                   marker='o', linewidth=2.5, markersize=8, color='#2E86AB')
    axes[0,0].fill_between(yearly_transfer['å¹´ä»½'], yearly_transfer['æ•°æ®ä¼ è¾“é‡_TB'], 
                           alpha=0.3, color='#2E86AB')
    axes[0,0].set_title('Total Data Transfer Volume (2019-2023)', fontsize=12, fontweight='bold')
    axes[0,0].set_xlabel('Year')
    axes[0,0].set_ylabel('Data Transfer (TB)')
    axes[0,0].grid(True, alpha=0.3)
    axes[0,0].set_xticks(yearly_transfer['å¹´ä»½'])
    
    # 2. å›¾2ï¼š2023å¹´Top10åŸå¸‚å¯¹ï¼ˆå³ä¸Šï¼‰
    top10_transfer['city_pair'] = top10_transfer['èµ·ç‚¹åŸå¸‚'] + 'â†’' + top10_transfer['ç»ˆç‚¹åŸå¸‚']
    bars = axes[0,1].barh(range(len(top10_transfer)), top10_transfer['æ•°æ®ä¼ è¾“é‡_TB'], 
                          color='#A23B72')
    axes[0,1].set_yticks(range(len(top10_transfer)))
    axes[0,1].set_yticklabels(top10_transfer['city_pair'], fontsize=10)
    axes[0,1].set_title('Top 10 City Pairs by Data Transfer (2023)', fontsize=12, fontweight='bold')
    axes[0,1].set_xlabel('Data Transfer (TB)')
    axes[0,1].grid(True, alpha=0.3, axis='x')
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        width = bar.get_width()
        axes[0,1].text(width + width*0.01, bar.get_y() + bar.get_height()/2, 
                       f'{width:.0f}', ha='left', va='center', fontsize=9)
    
    # 3. å›¾3ï¼šæ ¸å¿ƒåŸå¸‚æ•°å­—ç»æµå æ¯”ï¼ˆå·¦ä¸‹ï¼‰
    cities = core_econ['åŸå¸‚'].tolist()
    digital_ratios = core_econ['æ•°å­—ç»æµå GDPæ¯”é‡_%'].tolist()
    bars3 = axes[1,0].bar(cities, digital_ratios, color=['#F18F01', '#C73E1D', '#2E86AB', '#A23B72'])
    axes[1,0].set_title('Digital Economy Ratio in Core Cities (2023)', fontsize=12, fontweight='bold')
    axes[1,0].set_xlabel('City')
    axes[1,0].set_ylabel('Digital Economy / GDP (%)')
    axes[1,0].grid(True, alpha=0.3, axis='y')
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, ratio in zip(bars3, digital_ratios):
        height = bar.get_height()
        axes[1,0].text(bar.get_x() + bar.get_width()/2, height + 0.5, 
                       f'{ratio:.1f}%', ha='center', va='bottom', fontsize=10)
    
    # 4. å›¾4ï¼šæ•°æ®ä¸­å¿ƒä¸ç®—åŠ›å…³ç³»ï¼ˆå³ä¸‹ï¼‰
    scatter = axes[1,1].scatter(main_2023['æ•°æ®ä¸­å¿ƒæ•°é‡'], main_2023['ç®—åŠ›è§„æ¨¡_PFLOPS'], 
                               s=200, alpha=0.6, c=range(len(main_2023)), cmap='viridis')
    # æ·»åŠ åŸå¸‚æ ‡ç­¾
    for _, row in main_2023.iterrows():
        axes[1,1].annotate(row['åŸå¸‚'], (row['æ•°æ®ä¸­å¿ƒæ•°é‡'], row['ç®—åŠ›è§„æ¨¡_PFLOPS']),
                          xytext=(5, 5), textcoords='offset points', fontsize=9)
    axes[1,1].set_title('Data Centers vs Computing Power (2023)', fontsize=12, fontweight='bold')
    axes[1,1].set_xlabel('Number of Data Centers')
    axes[1,1].set_ylabel('Computing Power (PFLOPS)')
    axes[1,1].grid(True, alpha=0.3)
    
    # ä¿å­˜å›¾è¡¨
    plt.tight_layout()
    save_file = os.path.join(save_path, 'gba_digital_economy_analysis.png')
    plt.savefig(save_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜è‡³ï¼š{save_file}")

# ====================== 6. ä¸»å‡½æ•°ï¼ˆæµç¨‹æ§åˆ¶ï¼‰ ======================
def main():
    try:
        # 1. åˆå§‹åŒ–é…ç½®
        DATA_DIR = set_config()
        print("ğŸ”§ åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹æ•°æ®å¤„ç†...")
        
        # 2. åŠ è½½æ•°æ®
        data_dict = load_all_data(DATA_DIR)
        
        # 3. åŸºç¡€æ¢ç´¢
        basic_data_explore(data_dict)
        
        # 4. æ·±åº¦åˆ†æ
        analysis_results = deep_data_analysis(data_dict)
        
        # 5. ç”Ÿæˆå¯è§†åŒ–
        create_visualizations(analysis_results, DATA_DIR)
        
        print("\n" + "="*60)
        print("ğŸ‰ æ•°æ®åˆ†æå®Œæˆï¼ç”Ÿæˆæ–‡ä»¶ï¼š")
        print(f"   1. å¯è§†åŒ–å›¾è¡¨ï¼šgba_digital_economy_analysis.png")
        print(f"   2. åˆ†ææŠ¥å‘Šï¼šæ§åˆ¶å°è¾“å‡ºï¼ˆå¯å¤åˆ¶ä¿å­˜ï¼‰")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™ï¼š{str(e)}")

# æ‰§è¡Œä¸»å‡½æ•°
if __name__ == "__main__":
    main()
